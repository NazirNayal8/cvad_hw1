{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef1fa83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2179f90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/nazirnayal/Documents/courses/CV_AV/HW1/cvad_hw1'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "82c78b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "23efaaa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from models.cilrs import CILRS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0abba296",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ci = CILRS(cond_module='command_input')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5c446ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "B = 5\n",
    "x = torch.randn((B, 3, 88, 200))\n",
    "v = torch.randn((B,))\n",
    "c = torch.randint(0, 4, size=(B,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4714af4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5, 3, 88, 200]), torch.Size([5]), torch.Size([5]))"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape, v.shape, c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "003d0e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "th, st, br, v_o = model_ci(x, v, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "06cfda76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5]), torch.Size([5]), torch.Size([5]), torch.Size([5, 1]))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "th.shape, st.shape, br.shape, v_o.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "81f06d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_br = CILRS(cond_module='branched')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "28ea45e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "th, st, br, v_o = model_br(x, v, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4422374f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5]), torch.Size([5]), torch.Size([5]), torch.Size([5, 1]))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "th.shape, st.shape, br.shape, v_o.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "96e0c1ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.cilrs import one_hot_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6a95e4bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 0, 2, 0, 1])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9e141876",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0.]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_vector(c, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1e210fd",
   "metadata": {},
   "source": [
    "# Testing Util Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c512ad62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.lib.stride_tricks import as_strided"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e9d66a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tile_array(a, b0, b1):\n",
    "    r, c = a.shape                                    # number of rows/columns\n",
    "    rs, cs = a.strides                                # row/column strides\n",
    "    x = as_strided(a, (r, b0, c, b1), (rs, 0, cs, 0)) # view a as larger 4D array\n",
    "    return x.reshape(r*b0, c*b1)                      # create new 2D array\n",
    "\n",
    "def get_bool_vec(d, n_h):\n",
    "    # first one hot encode to three possible classes\n",
    "    t = np.zeros((len(d), 3))\n",
    "    t[np.arange(len(d)), d+1] = 1\n",
    "    # upscale to correct hidden_sz\n",
    "    print(t)\n",
    "    bool_vec = tile_array(t, 1, n_h//3)\n",
    "    return torch.Tensor(bool_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3d45e6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randint(0, 2, size=(5,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ff72aca4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "one_hot = get_bool_vec(x, 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b31bb316",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1.],\n",
       "         [0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 0.]]),\n",
       " torch.Size([5, 12]))"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot, one_hot.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e709d43",
   "metadata": {},
   "source": [
    "# Testing Affordance Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "dc8ec377",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.affordance_predictor import AffordancePredictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1539ac7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_aff = AffordancePredictor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "44870b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn((5, 3, 224, 224))\n",
    "c = torch.randint(0, 4, size=(5,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "cc112750",
   "metadata": {},
   "outputs": [],
   "source": [
    "lane_dist, route_angle, tl_dist, tl_state = model_aff(x, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c4030a33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5, 1]),\n",
       " torch.Size([5, 1]),\n",
       " torch.Size([5, 1]),\n",
       " torch.Size([5, 2]))"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lane_dist.shape, route_angle.shape, tl_dist.shape, tl_state.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c08d893d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rewards = np.array([0, 10, -20, 10, 100, 10, 30, 50, 10, -100, -50, 10, 0, 0, 0, 0])\n",
    "Q_2 = np.zeros(len(rewards))\n",
    "Q_3 = np.zeros(len(rewards))\n",
    "lr = 0.5;\n",
    "num_states = len(rewards) - 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8faac2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in reversed(range(num_states)):\n",
    "    \n",
    "    Q_2[i] = (1 - lr) * Q_2[i] + lr * (rewards[i + 2] + max())\n",
    " \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nazir_env",
   "language": "python",
   "name": "nazir_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
